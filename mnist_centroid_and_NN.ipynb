{
 "cells": [
  {
   "cell_type": "raw",
   "id": "603a8e96",
   "metadata": {},
   "source": [
    "                                          Supervised Learning   || Assignment 2\n",
    "    \n",
    "Abanoub Samir Girgis  || 20190001\n",
    "Joyce Fayek Milad     || 20190160\n",
    "Group: S2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d675d216",
   "metadata": {},
   "source": [
    "# Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623d02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c4542",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c24944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(x_train,y_train) , (x_test ,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015c35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 1000\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[:10000,:,:]\n",
    "x_test = x_test[:1000,:,:]\n",
    "y_train = y_train[:10000]\n",
    "y_test  = y_test[:1000]\n",
    "\n",
    "print(len(x_train), len(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f5c8c",
   "metadata": {},
   "source": [
    "# showing a sample of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2977c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANR0lEQVR4nO3dX4xc5X3G8efxsjbBCYrX1M7GOEAJlkor1VSLqeJAqUgRQakMSoJiKakroToXsRSkXEBpq1DloiRqQqM2QnLAjVMloFQJwhckxVgoCCVyvBAX2zUthBowdr1OncgmmPWf/fViD9Vids6M55yZM97f9yONZva8c+Y8GvnxmZ13Zl9HhADMffOaDgCgPyg7kARlB5Kg7EASlB1I4rx+Hmy+F8T5WtjPQwKpvKnf6ERMeraxSmW3fZOkr0sakvRARNxbdv/ztVDX+IYqhwRQYntsaznW9ct420OSviHpo5KulLTW9pXdPh6A3qryO/sqSS9GxEsRcULSw5LW1BMLQN2qlH2ZpFdn/Ly/2PY2ttfbHrc9flKTFQ4HoIoqZZ/tTYB3fPY2IjZGxFhEjA1rQYXDAaiiStn3S1o+4+eLJR2oFgdAr1Qp+w5JV9i+zPZ8SZ+StKWeWADq1vXUW0Scsr1B0r9peuptU0TsqS0ZgFpVmmePiMckPVZTFgA9xMdlgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSKLSKq7AIPvNJ65pOfblr9xfuu+Xbvuz0vEY391VpiZVKrvtfZKOSTot6VREjNURCkD96jiz/3FE/LKGxwHQQ/zODiRRtewh6XHbz9heP9sdbK+3PW57/KQmKx4OQLeqvoxfHREHbC+RtNX28xHx1Mw7RMRGSRsl6UKPRMXjAehSpTN7RBworickPSJpVR2hANSv67LbXmj7PW/dlnSjpHNvPgJIosrL+KWSHrH91uN8NyJ+VEuqHji+pvxFx/HFQ6XjI5t+Wmcc9MHEWOtz2Zf2/WkfkwyGrsseES9J+v0aswDoIabegCQoO5AEZQeSoOxAEpQdSCLNV1wPXFf+/9oFl/+6/AE21ZcFNZlXPl0aHzjecuyGJc+X7rvNH+oq0iDjzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSaSZZ//bj/1r6fiX997YpySoy9Dll5SOP/9HrT8csfJnny7d9/07dnWVaZBxZgeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJNLMsw/7VNMRULPzHnij632P/+LCGpOcGzizA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASc2aeferDK0vHrz3/6f4EQd9cuvB/u953+ROna0xybmh7Zre9yfaE7d0zto3Y3mr7heJ6UW9jAqiqk5fx35J00xnb7pK0LSKukLSt+BnAAGtb9oh4StKRMzavkbS5uL1Z0i31xgJQt27foFsaEQclqbhe0uqOttfbHrc9flKTXR4OQFU9fzc+IjZGxFhEjA1rQa8PB6CFbst+yPaoJBXXE/VFAtAL3ZZ9i6R1xe11kh6tJw6AXmk7z277IUnXS7rI9n5JX5R0r6Tv2b5d0iuSPtnLkJ14+WPvKh1fMnRBn5KgLudd+oHS8U+MbOn6sd/1378qHZ+Ls/Btyx4Ra1sM3VBzFgA9xMdlgSQoO5AEZQeSoOxAEpQdSGLOfMX1vA8eq7T/m8+/t54gqM2r/7CwdHz1gqnS8QePXtx68NdHu4l0TuPMDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJzJl59qqWjJfP2WJ2QxctLh0/9PEVLcdGbttfuu+PVzzY5ujnl47e/41bWo4tOfSTNo8993BmB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkmGcvHB8p/3+v/JvV1Uxde1XpeAy5dPzVj7ReaefE+0+W7jtvfvkfTX782n8sHR8uj6b/Od0629+8dGvpvkemyj/7cMG88uxLt7f+GwdRuufcxJkdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5KYM/Psk28Ol45PtZlZ/ee77ysd37Jh5dlG6tidix8oHZ+n8sns43Gi5diB0+Vz0f90+PrS8Y88cUfp+Ht/Pr90fPTxQy3H/HL599kP7y1fhnvpUPlnCGLHrtLxbNqe2W1vsj1he/eMbffYfs32zuJyc29jAqiqk5fx35J00yzb74uIlcXlsXpjAahb27JHxFOSjvQhC4AeqvIG3QbbzxUv8xe1upPt9bbHbY+f1GSFwwGootuy3y/pckkrJR2U9NVWd4yIjRExFhFjw2r9pQgAvdVV2SPiUEScjogpSd+UtKreWADq1lXZbY/O+PFWSbtb3RfAYGg7z277IUnXS7rI9n5JX5R0ve2Vmv5a8D5Jn+1dxM588NM/Lx3/3b/bUDq+/OrX6oxzVp6caP231SXp8A9L1hmXtHhP6/nm+T/a0ebo5XPVKzTeZv9yZbP8r935odJ9r17w09Lxh19f1kWivNqWPSLWzrK53V/vBzBg+LgskARlB5Kg7EASlB1IgrIDScyZr7i2c9lflk/jDLJRvdJ0hJ644LrDlfb/6yc/Xjq+Qj+r9PhzDWd2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUgizTw75p5LHs248HL3OLMDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEnyfHQNryOXnol+tGC4df98P60xz7mt7Zre93PaTtvfa3mP788X2Edtbbb9QXC/qfVwA3erkZfwpSV+IiN+R9IeSPmf7Skl3SdoWEVdI2lb8DGBAtS17RByMiGeL28ck7ZW0TNIaSZuLu22WdEuPMgKowVm9QWf7UklXSdouaWlEHJSm/0OQtKTFPuttj9seP6nJinEBdKvjstt+t6TvS7ojIo52ul9EbIyIsYgYG9aCbjICqEFHZbc9rOmifyciflBsPmR7tBgflTTRm4gA6tDJu/GW9KCkvRHxtRlDWyStK26vk/Ro/fGQ2emYKr1onsoveJtO5tlXS/qMpF22dxbb7pZ0r6Tv2b5d0iuSPtmThABq0bbsEfG0JLcYvqHeOAB6hRc7QBKUHUiCsgNJUHYgCcoOJMFXXHHOeuPqN5qOcE7hzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSTDPjoHV7k9J4+zwbAJJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEsyzozGTT/xW6fjplVN9SpIDZ3YgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSMIRUX4He7mkb0t6n6QpSRsj4uu275H0F5IOF3e9OyIeK3usCz0S15iFX4Fe2R7bdDSOzLrqcicfqjkl6QsR8azt90h6xvbWYuy+iPj7uoIC6J1O1mc/KOlgcfuY7b2SlvU6GIB6ndXv7LYvlXSVpO3Fpg22n7O9yfaiFvustz1ue/ykJqulBdC1jstu+92Svi/pjog4Kul+SZdLWqnpM/9XZ9svIjZGxFhEjA1rQfXEALrSUdltD2u66N+JiB9IUkQciojTETEl6ZuSVvUuJoCq2pbdtiU9KGlvRHxtxvbRGXe7VdLu+uMBqEsn78avlvQZSbts7yy23S1pre2VkkLSPkmf7UE+ADXp5N34pyXNNm9XOqcOYLDwCTogCcoOJEHZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASbf+UdK0Hsw9LennGposk/bJvAc7OoGYb1FwS2bpVZ7ZLImLWtbD7WvZ3HNwej4ixxgKUGNRsg5pLIlu3+pWNl/FAEpQdSKLpsm9s+PhlBjXboOaSyNatvmRr9Hd2AP3T9JkdQJ9QdiCJRspu+ybb/2n7Rdt3NZGhFdv7bO+yvdP2eMNZNtmesL17xrYR21ttv1Bcz7rGXkPZ7rH9WvHc7bR9c0PZltt+0vZe23tsf77Y3uhzV5KrL89b339ntz0k6b8k/Ymk/ZJ2SFobEf/R1yAt2N4naSwiGv8Ahu3rJL0u6dsR8XvFtq9IOhIR9xb/US6KiDsHJNs9kl5vehnvYrWi0ZnLjEu6RdKfq8HnriTXberD89bEmX2VpBcj4qWIOCHpYUlrGsgx8CLiKUlHzti8RtLm4vZmTf9j6bsW2QZCRByMiGeL28ckvbXMeKPPXUmuvmii7MskvTrj5/0arPXeQ9Ljtp+xvb7pMLNYGhEHpel/PJKWNJznTG2X8e6nM5YZH5jnrpvlz6tqouyzLSU1SPN/qyPiDyR9VNLniper6ExHy3j3yyzLjA+Ebpc/r6qJsu+XtHzGzxdLOtBAjllFxIHiekLSIxq8pagPvbWCbnE90XCe/zdIy3jPtsy4BuC5a3L58ybKvkPSFbYvsz1f0qckbWkgxzvYXli8cSLbCyXdqMFbinqLpHXF7XWSHm0wy9sMyjLerZYZV8PPXePLn0dE3y+Sbtb0O/K/kPRXTWRokeu3Jf17cdnTdDZJD2n6Zd1JTb8iul3SYknbJL1QXI8MULZ/kbRL0nOaLtZoQ9k+rOlfDZ+TtLO43Nz0c1eSqy/PGx+XBZLgE3RAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kMT/AT3d83+88ik1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d180dc",
   "metadata": {},
   "source": [
    "# split the image into grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdd3b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockshaped(arr, nrows, ncols):\n",
    "    h, w = arr.shape\n",
    "    grid = (arr.reshape(h//nrows, nrows, -1, ncols)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, nrows, ncols))\n",
    "    return grid\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78149639",
   "metadata": {},
   "source": [
    "# get the centroid for each grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f08843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(grid):\n",
    "    Mx = 0\n",
    "    My = 0\n",
    "    mass = 0\n",
    "    for i in range(len(grid)):\n",
    "        for j in range(len(grid[i])):\n",
    "            if grid[i][j]:\n",
    "                Mx += j\n",
    "                My += i\n",
    "                mass += 1\n",
    "        if mass==0:\n",
    "            mass=1\n",
    "    point = (float(Mx)/mass , float(My)/mass)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55791f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e3c32",
   "metadata": {},
   "source": [
    "# Applying the functions on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ef8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b68e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic in x_train:\n",
    "    grid=blockshaped(pic,cols ,cols)\n",
    "    train_vector.append([centroid(x) for x in grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb9b3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector=np.array(train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b66341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vector=train_vector.reshape(10000,len(train_vector[0])*2,1)\n",
    "train_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793916e",
   "metadata": {},
   "source": [
    "# Applying the functions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61619fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15760da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic in x_test:\n",
    "    grid=blockshaped(pic, cols , cols)\n",
    "    test_vector.append([centroid(x) for x in grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "493ffb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector=np.array(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330301bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector=test_vector.reshape(1000,len(test_vector[0])*2,1)\n",
    "test_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849c6dc",
   "metadata": {},
   "source": [
    "# apply one hot encoder representation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcffc260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape=(10000, 32, 1)\n",
      "train_label shape=(10000, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "train_label = np.zeros((10000, 10,1))\n",
    "for col in range (10000):\n",
    "    val=y_train[col]\n",
    "    for row in range (10):\n",
    "        if (val==row):\n",
    "            train_label[col][row]=1\n",
    "\n",
    "print(\"train_data shape=\"+str(np.shape(train_vector)))\n",
    "print(\"train_label shape=\"+str(np.shape(train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb680e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data shape=(1000, 32, 1)\n",
      "test_label shape=(1000, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "test_label = np.zeros((1000, 10,1))\n",
    "for col in range (1000):\n",
    "    val=y_test[col]\n",
    "    for row in range (10):\n",
    "        if (val==row):\n",
    "            test_label[col,val]=1\n",
    "print(\"test_data shape=\"+str(np.shape(test_vector)))\n",
    "print(\"test_label shape=\"+str(np.shape(test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc779b",
   "metadata": {},
   "source": [
    "# apply NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d6fe68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(number_of_layers,output_layer):\n",
    "    weights=[]\n",
    "\n",
    "    for i in range(number_of_layers):\n",
    "        if i==0:\n",
    "            w= input(\"Please enter number of neurons in the first hidden layer:\")\n",
    "            w= int(w)\n",
    "            W1 = np.random.randn(w, len(train_vector[0])) \n",
    "            weights.append(W1)\n",
    "        elif i==(number_of_layers-1):\n",
    "            output = np.random.randn(output_layer, len(weights[i-1]))\n",
    "            weights.append(output)\n",
    "            break\n",
    "        else:\n",
    "            print(\"for hidden layer \", i+1)\n",
    "            w= input(\"Please enter number of neurons in the hidden layer:\")\n",
    "            w= int(w)\n",
    "            W1 = np.random.randn(w, len(weights[i-1]))\n",
    "            weights.append(W1)\n",
    "    return weights\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return  1/(1 + np.exp(-Z))\n",
    "\n",
    "def normalization(x):\n",
    "    sum=0\n",
    "    for i in range(len(x)):\n",
    "        sum+=x[i]\n",
    "    for i in range(len(x)):\n",
    "        x[i]=x[i]/sum\n",
    "    return x\n",
    "\n",
    "def MSE(actual,predicted):\n",
    "    sum = 0  \n",
    "    n = len(actual) \n",
    "    for i in range (0,n):  \n",
    "        difference = actual[i] - predicted[i]  \n",
    "        squared_difference = difference**2  \n",
    "        sum = sum + squared_difference  \n",
    "    MSE = sum/n  \n",
    "    return MSE\n",
    "def get_index(x):\n",
    "    index=0\n",
    "    max=x[0]\n",
    "    for i in range(10):\n",
    "        if max<x[i]:\n",
    "            max=x[i]\n",
    "            index=i\n",
    "    return index\n",
    "\n",
    "def forward_prop(weights,X):\n",
    "    Z=[]\n",
    "    A=[]\n",
    "    Z.append(weights[0].dot(X))\n",
    "    A.append(sigmoid(Z[0]))\n",
    "    for i in range(1,len(weights)):\n",
    "        Z.append(weights[i].dot(A[i-1]))\n",
    "        A.append(sigmoid(Z[i]))\n",
    "    A[len(weights)-1]=normalization(A[len(weights)-1])\n",
    "\n",
    "    return Z,A\n",
    "\n",
    "def sigmoid_deriv(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "\n",
    "def backward_prop(Z,A,weights,alpha, X, train_label):\n",
    "    dweights=[0] * (len(weights))\n",
    "    dZ=[0] * (len(weights))\n",
    "    \n",
    "    #output layer\n",
    "    error=train_label-A[len(weights)-1]\n",
    "    dZ[(len(weights)-1)]=error*sigmoid_deriv(Z[len(weights)-1])\n",
    "    dweights[(len(weights)-1)]=alpha* dZ[(len(weights)-1)].dot(A[(len(weights)-1)-1].T)    \n",
    "    \n",
    "    #all hidden layers except the first one\n",
    "    for i in range((len(weights)-2),0,-1):\n",
    "        dZ[i]=weights[i+1].T.dot(dZ[i+1]) * sigmoid_deriv(Z[i])  \n",
    "        dweights[i]=alpha * dZ[i].dot(A[i-1].T)\n",
    "        \n",
    "    #the first hidden layer\n",
    "    dZ[0]=weights[1].T.dot(dZ[1]) * sigmoid_deriv(Z[0])  \n",
    "    dweights[0]=alpha * dZ[0].dot(X.T)\n",
    "    return dweights\n",
    "\n",
    "def update_params(weights,dweights, alpha):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i]=weights[i]+dweights[i]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32cd68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, weights):\n",
    "    Z,A = forward_prop(weights, X)\n",
    "    return A[len(weights)-1]\n",
    "\n",
    "def get_accuracy(actual, predicted1):\n",
    "    correct = 0\n",
    "    predicted=[]\n",
    "    for i in range(len(predicted1)):\n",
    "        x=get_index(predicted1[i])\n",
    "        predicted.append(x)\n",
    "        \n",
    "    for i in range(len(predicted)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "def training_fit(X, Y, hidden_layers,alpha,iterations):\n",
    "    weights = init_params(hidden_layers,10)\n",
    "\n",
    "    actual=[]\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        x=get_index(Y[i])\n",
    "        actual.append(x)\n",
    "    \n",
    "    for j in range(iterations):\n",
    "        print(\"Iteration: \",j)\n",
    "        predictions=[]\n",
    "        error=0\n",
    "        for i in range(len(X)):\n",
    "            Z,A = forward_prop(weights, X[i])\n",
    "            error+=MSE(A[len(weights)-1],Y[i])\n",
    "            dweights= backward_prop(Z,A,weights, alpha,X[i], Y[i])\n",
    "            weights = update_params(weights,dweights, alpha)\n",
    "            predictions.append(make_predictions(X[i],weights))\n",
    "        print(\"Error: \",error/len(X))\n",
    "        print(\"Training Accuracy: \",get_accuracy(actual,predictions),\" %\")\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29643416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter number of neurons in the first hidden layer:40\n",
      "for hidden layer  2\n",
      "Please enter number of neurons in the hidden layer:24\n",
      "Iteration:  0\n",
      "Error:  [0.08989191]\n",
      "Training Accuracy:  22.67  %\n",
      "Iteration:  1\n",
      "Error:  [0.0781266]\n",
      "Training Accuracy:  42.370000000000005  %\n",
      "Iteration:  2\n",
      "Error:  [0.07227411]\n",
      "Training Accuracy:  51.25999999999999  %\n",
      "Iteration:  3\n",
      "Error:  [0.0670883]\n",
      "Training Accuracy:  57.64  %\n",
      "Iteration:  4\n",
      "Error:  [0.06205672]\n",
      "Training Accuracy:  62.38  %\n",
      "Iteration:  5\n",
      "Error:  [0.05807374]\n",
      "Training Accuracy:  64.87  %\n",
      "Iteration:  6\n",
      "Error:  [0.05474544]\n",
      "Training Accuracy:  66.60000000000001  %\n",
      "Iteration:  7\n",
      "Error:  [0.05182486]\n",
      "Training Accuracy:  68.97  %\n",
      "Iteration:  8\n",
      "Error:  [0.04913448]\n",
      "Training Accuracy:  71.09  %\n",
      "Iteration:  9\n",
      "Error:  [0.04662476]\n",
      "Training Accuracy:  73.09  %\n",
      "Iteration:  10\n",
      "Error:  [0.04432895]\n",
      "Training Accuracy:  74.83  %\n",
      "Iteration:  11\n",
      "Error:  [0.04227955]\n",
      "Training Accuracy:  76.05  %\n",
      "Iteration:  12\n",
      "Error:  [0.04045009]\n",
      "Training Accuracy:  77.27000000000001  %\n",
      "Iteration:  13\n",
      "Error:  [0.03881092]\n",
      "Training Accuracy:  78.53  %\n",
      "Iteration:  14\n",
      "Error:  [0.03734121]\n",
      "Training Accuracy:  79.36  %\n",
      "Iteration:  15\n",
      "Error:  [0.03601949]\n",
      "Training Accuracy:  80.15  %\n",
      "Iteration:  16\n",
      "Error:  [0.03482095]\n",
      "Training Accuracy:  80.78999999999999  %\n",
      "Iteration:  17\n",
      "Error:  [0.03372368]\n",
      "Training Accuracy:  81.42  %\n",
      "Iteration:  18\n",
      "Error:  [0.03271018]\n",
      "Training Accuracy:  81.89999999999999  %\n",
      "Iteration:  19\n",
      "Error:  [0.03177225]\n",
      "Training Accuracy:  82.34  %\n",
      "Iteration:  20\n",
      "Error:  [0.03090919]\n",
      "Training Accuracy:  82.82000000000001  %\n",
      "Iteration:  21\n",
      "Error:  [0.03012065]\n",
      "Training Accuracy:  83.37  %\n",
      "Iteration:  22\n",
      "Error:  [0.02940472]\n",
      "Training Accuracy:  83.67  %\n",
      "Iteration:  23\n",
      "Error:  [0.02875394]\n",
      "Training Accuracy:  83.99  %\n",
      "Iteration:  24\n",
      "Error:  [0.02815942]\n",
      "Training Accuracy:  84.31  %\n",
      "Iteration:  25\n",
      "Error:  [0.02761434]\n",
      "Training Accuracy:  84.67  %\n",
      "Iteration:  26\n",
      "Error:  [0.02711353]\n",
      "Training Accuracy:  85.00999999999999  %\n",
      "Iteration:  27\n",
      "Error:  [0.02665283]\n",
      "Training Accuracy:  85.35000000000001  %\n",
      "Iteration:  28\n",
      "Error:  [0.02622826]\n",
      "Training Accuracy:  85.55  %\n",
      "Iteration:  29\n",
      "Error:  [0.02583575]\n",
      "Training Accuracy:  85.7  %\n",
      "Iteration:  30\n",
      "Error:  [0.02547147]\n",
      "Training Accuracy:  85.87  %\n",
      "Iteration:  31\n",
      "Error:  [0.02513199]\n",
      "Training Accuracy:  86.07000000000001  %\n",
      "Iteration:  32\n",
      "Error:  [0.0248144]\n",
      "Training Accuracy:  86.14  %\n",
      "Iteration:  33\n",
      "Error:  [0.0245163]\n",
      "Training Accuracy:  86.29  %\n",
      "Iteration:  34\n",
      "Error:  [0.02423569]\n",
      "Training Accuracy:  86.39  %\n",
      "Iteration:  35\n",
      "Error:  [0.02397088]\n",
      "Training Accuracy:  86.47  %\n",
      "Iteration:  36\n",
      "Error:  [0.02372047]\n",
      "Training Accuracy:  86.67  %\n",
      "Iteration:  37\n",
      "Error:  [0.02348341]\n",
      "Training Accuracy:  86.76  %\n",
      "Iteration:  38\n",
      "Error:  [0.02325883]\n",
      "Training Accuracy:  86.86  %\n",
      "Iteration:  39\n",
      "Error:  [0.02304597]\n",
      "Training Accuracy:  87.05000000000001  %\n",
      "Iteration:  40\n",
      "Error:  [0.02284405]\n",
      "Training Accuracy:  87.12  %\n",
      "Iteration:  41\n",
      "Error:  [0.02265227]\n",
      "Training Accuracy:  87.2  %\n",
      "Iteration:  42\n",
      "Error:  [0.02246981]\n",
      "Training Accuracy:  87.2  %\n",
      "Iteration:  43\n",
      "Error:  [0.02229594]\n",
      "Training Accuracy:  87.28  %\n",
      "Iteration:  44\n",
      "Error:  [0.02212997]\n",
      "Training Accuracy:  87.41  %\n",
      "Iteration:  45\n",
      "Error:  [0.02197127]\n",
      "Training Accuracy:  87.46000000000001  %\n",
      "Iteration:  46\n",
      "Error:  [0.02181917]\n",
      "Training Accuracy:  87.5  %\n",
      "Iteration:  47\n",
      "Error:  [0.02167299]\n",
      "Training Accuracy:  87.6  %\n",
      "Iteration:  48\n",
      "Error:  [0.02153215]\n",
      "Training Accuracy:  87.66000000000001  %\n",
      "Iteration:  49\n",
      "Error:  [0.02139649]\n",
      "Training Accuracy:  87.75  %\n",
      "Iteration:  50\n",
      "Error:  [0.02126629]\n",
      "Training Accuracy:  87.83999999999999  %\n",
      "Iteration:  51\n",
      "Error:  [0.02114165]\n",
      "Training Accuracy:  87.83  %\n",
      "Iteration:  52\n",
      "Error:  [0.02102246]\n",
      "Training Accuracy:  87.85  %\n",
      "Iteration:  53\n",
      "Error:  [0.02090867]\n",
      "Training Accuracy:  87.87  %\n",
      "Iteration:  54\n",
      "Error:  [0.02080035]\n",
      "Training Accuracy:  87.94  %\n",
      "Iteration:  55\n",
      "Error:  [0.02069752]\n",
      "Training Accuracy:  87.99  %\n",
      "Iteration:  56\n",
      "Error:  [0.02060022]\n",
      "Training Accuracy:  88.03999999999999  %\n",
      "Iteration:  57\n",
      "Error:  [0.02050839]\n",
      "Training Accuracy:  88.14  %\n",
      "Iteration:  58\n",
      "Error:  [0.02042175]\n",
      "Training Accuracy:  88.19  %\n",
      "Iteration:  59\n",
      "Error:  [0.02033979]\n",
      "Training Accuracy:  88.17  %\n",
      "Iteration:  60\n",
      "Error:  [0.02026193]\n",
      "Training Accuracy:  88.12  %\n",
      "Iteration:  61\n",
      "Error:  [0.02018758]\n",
      "Training Accuracy:  88.13  %\n",
      "Iteration:  62\n",
      "Error:  [0.02011623]\n",
      "Training Accuracy:  88.22  %\n",
      "Iteration:  63\n",
      "Error:  [0.02004749]\n",
      "Training Accuracy:  88.28  %\n",
      "Iteration:  64\n",
      "Error:  [0.01998104]\n",
      "Training Accuracy:  88.23  %\n",
      "Iteration:  65\n",
      "Error:  [0.01991666]\n",
      "Training Accuracy:  88.26  %\n",
      "Iteration:  66\n",
      "Error:  [0.01985417]\n",
      "Training Accuracy:  88.27000000000001  %\n",
      "Iteration:  67\n",
      "Error:  [0.01979349]\n",
      "Training Accuracy:  88.33  %\n",
      "Iteration:  68\n",
      "Error:  [0.01973453]\n",
      "Training Accuracy:  88.39  %\n",
      "Iteration:  69\n",
      "Error:  [0.01967726]\n",
      "Training Accuracy:  88.38000000000001  %\n",
      "Iteration:  70\n",
      "Error:  [0.01962167]\n",
      "Training Accuracy:  88.41  %\n",
      "Iteration:  71\n",
      "Error:  [0.01956772]\n",
      "Training Accuracy:  88.42  %\n",
      "Iteration:  72\n",
      "Error:  [0.01951541]\n",
      "Training Accuracy:  88.44999999999999  %\n",
      "Iteration:  73\n",
      "Error:  [0.01946472]\n",
      "Training Accuracy:  88.47  %\n",
      "Iteration:  74\n",
      "Error:  [0.01941562]\n",
      "Training Accuracy:  88.46000000000001  %\n",
      "Iteration:  75\n",
      "Error:  [0.01936804]\n",
      "Training Accuracy:  88.47  %\n",
      "Iteration:  76\n",
      "Error:  [0.01932192]\n",
      "Training Accuracy:  88.5  %\n",
      "Iteration:  77\n",
      "Error:  [0.01927715]\n",
      "Training Accuracy:  88.55  %\n",
      "Iteration:  78\n",
      "Error:  [0.01923363]\n",
      "Training Accuracy:  88.6  %\n",
      "Iteration:  79\n",
      "Error:  [0.01919127]\n",
      "Training Accuracy:  88.59  %\n",
      "Iteration:  80\n",
      "Error:  [0.01914998]\n",
      "Training Accuracy:  88.59  %\n",
      "Iteration:  81\n",
      "Error:  [0.01910971]\n",
      "Training Accuracy:  88.6  %\n",
      "Iteration:  82\n",
      "Error:  [0.01907045]\n",
      "Training Accuracy:  88.6  %\n",
      "Iteration:  83\n",
      "Error:  [0.01903221]\n",
      "Training Accuracy:  88.63  %\n",
      "Iteration:  84\n",
      "Error:  [0.018995]\n",
      "Training Accuracy:  88.62  %\n",
      "Iteration:  85\n",
      "Error:  [0.01895887]\n",
      "Training Accuracy:  88.6  %\n",
      "Iteration:  86\n",
      "Error:  [0.01892384]\n",
      "Training Accuracy:  88.62  %\n",
      "Iteration:  87\n",
      "Error:  [0.01888995]\n",
      "Training Accuracy:  88.58  %\n",
      "Iteration:  88\n",
      "Error:  [0.01885723]\n",
      "Training Accuracy:  88.55  %\n",
      "Iteration:  89\n",
      "Error:  [0.01882572]\n",
      "Training Accuracy:  88.57000000000001  %\n",
      "Iteration:  90\n",
      "Error:  [0.01879542]\n",
      "Training Accuracy:  88.55  %\n",
      "Iteration:  91\n",
      "Error:  [0.01876636]\n",
      "Training Accuracy:  88.56  %\n",
      "Iteration:  92\n",
      "Error:  [0.01873852]\n",
      "Training Accuracy:  88.5  %\n",
      "Iteration:  93\n",
      "Error:  [0.01871189]\n",
      "Training Accuracy:  88.52  %\n",
      "Iteration:  94\n",
      "Error:  [0.01868646]\n",
      "Training Accuracy:  88.56  %\n",
      "Iteration:  95\n",
      "Error:  [0.01866218]\n",
      "Training Accuracy:  88.55  %\n",
      "Iteration:  96\n",
      "Error:  [0.01863901]\n",
      "Training Accuracy:  88.57000000000001  %\n",
      "Iteration:  97\n",
      "Error:  [0.01861685]\n",
      "Training Accuracy:  88.57000000000001  %\n",
      "Iteration:  98\n",
      "Error:  [0.01859562]\n",
      "Training Accuracy:  88.59  %\n",
      "Iteration:  99\n",
      "Error:  [0.01857518]\n",
      "Training Accuracy:  88.6  %\n"
     ]
    }
   ],
   "source": [
    "X_train=train_vector[:10000,:]\n",
    "Y_train=train_label[:10000,:]\n",
    "X_test=test_vector[:1000,:]\n",
    "Y_test=test_label[:1000,:]\n",
    "numberOf_layers=3\n",
    "weights= training_fit(X_train,Y_train,numberOf_layers,0.01,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb724ab",
   "metadata": {},
   "source": [
    "# testing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa5b97ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  83.2  %\n"
     ]
    }
   ],
   "source": [
    "actual=[]\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    x=get_index(Y_test[i])\n",
    "    actual.append(x)\n",
    "    \n",
    "predictions=[]\n",
    "for i in range(len(X_test)):\n",
    "    A3=make_predictions(X_test[i], weights)\n",
    "    predictions.append(A3)\n",
    "\n",
    "print(\"Test Accuracy: \",get_accuracy(actual,predictions),\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84897c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  7\n",
      "2  2\n",
      "1  1\n",
      "0  0\n",
      "4  4\n",
      "1  1\n",
      "4  4\n",
      "9  9\n",
      "5  5\n",
      "9  9\n",
      "0  0\n",
      "6  6\n",
      "9  9\n",
      "0  0\n",
      "1  1\n",
      "5  8\n",
      "9  9\n",
      "7  7\n",
      "3  6\n",
      "4  4\n",
      "9  9\n",
      "6  6\n",
      "6  6\n",
      "5  5\n",
      "4  4\n",
      "0  0\n",
      "7  7\n",
      "4  4\n",
      "0  0\n",
      "1  1\n",
      "3  3\n",
      "1  1\n",
      "3  3\n",
      "4  4\n",
      "7  7\n",
      "2  2\n",
      "7  7\n",
      "1  1\n",
      "2  3\n",
      "1  1\n",
      "1  1\n",
      "7  7\n",
      "4  4\n",
      "2  2\n",
      "3  3\n",
      "5  8\n",
      "1  1\n",
      "2  2\n",
      "4  4\n",
      "4  4\n",
      "6  6\n",
      "3  6\n",
      "5  5\n",
      "5  8\n",
      "6  6\n",
      "0  0\n",
      "4  4\n",
      "1  1\n",
      "9  9\n",
      "5  5\n",
      "7  7\n",
      "8  8\n",
      "9  9\n",
      "3  3\n",
      "7  7\n",
      "4  9\n",
      "6  6\n",
      "4  4\n",
      "3  3\n",
      "0  0\n",
      "7  7\n",
      "0  0\n",
      "2  2\n",
      "9  7\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "2  2\n",
      "9  9\n",
      "7  7\n",
      "7  7\n",
      "6  6\n",
      "2  2\n",
      "7  7\n",
      "8  8\n",
      "4  4\n",
      "7  7\n",
      "3  6\n",
      "6  6\n",
      "1  1\n",
      "3  3\n",
      "6  6\n",
      "9  9\n",
      "3  3\n",
      "1  1\n",
      "4  8\n",
      "1  6\n",
      "7  9\n",
      "6  6\n",
      "9  9\n",
      "6  6\n",
      "0  0\n",
      "5  5\n",
      "4  4\n",
      "9  9\n",
      "9  9\n",
      "2  2\n",
      "1  1\n",
      "9  9\n",
      "4  4\n",
      "8  8\n",
      "7  7\n",
      "3  3\n",
      "9  9\n",
      "7  7\n",
      "4  4\n",
      "4  4\n",
      "4  4\n",
      "9  9\n",
      "2  8\n",
      "5  3\n",
      "4  4\n",
      "7  7\n",
      "6  6\n",
      "7  4\n",
      "9  9\n",
      "0  0\n",
      "5  5\n",
      "8  8\n",
      "5  5\n",
      "6  6\n",
      "6  6\n",
      "5  6\n",
      "7  7\n",
      "8  8\n",
      "1  1\n",
      "0  0\n",
      "1  1\n",
      "6  6\n",
      "4  4\n",
      "6  6\n",
      "7  7\n",
      "3  3\n",
      "1  1\n",
      "7  7\n",
      "1  1\n",
      "8  8\n",
      "2  2\n",
      "0  0\n",
      "2  2\n",
      "9  4\n",
      "9  4\n",
      "5  5\n",
      "5  0\n",
      "1  1\n",
      "5  5\n",
      "6  6\n",
      "0  0\n",
      "3  3\n",
      "4  7\n",
      "4  8\n",
      "6  6\n",
      "5  5\n",
      "4  4\n",
      "6  6\n",
      "5  6\n",
      "4  4\n",
      "5  5\n",
      "1  1\n",
      "4  4\n",
      "4  4\n",
      "7  7\n",
      "2  2\n",
      "3  0\n",
      "2  2\n",
      "7  7\n",
      "1  1\n",
      "8  8\n",
      "1  1\n",
      "8  8\n",
      "1  1\n",
      "8  8\n",
      "5  5\n",
      "0  0\n",
      "8  8\n",
      "9  4\n",
      "2  2\n",
      "5  3\n",
      "0  0\n",
      "1  1\n",
      "1  1\n",
      "1  1\n",
      "0  0\n",
      "9  9\n",
      "0  0\n",
      "3  9\n",
      "1  1\n",
      "6  6\n",
      "4  4\n",
      "2  2\n",
      "3  3\n",
      "6  6\n",
      "1  1\n",
      "1  1\n",
      "1  1\n",
      "3  3\n",
      "9  4\n",
      "5  3\n",
      "2  2\n",
      "9  9\n",
      "4  4\n",
      "5  5\n",
      "9  7\n",
      "3  3\n",
      "9  9\n",
      "0  0\n",
      "3  3\n",
      "6  6\n",
      "5  3\n",
      "5  5\n",
      "7  7\n",
      "2  2\n",
      "2  3\n",
      "7  7\n",
      "1  1\n",
      "2  2\n",
      "8  8\n",
      "4  4\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "3  3\n",
      "8  8\n",
      "8  8\n",
      "7  7\n",
      "9  9\n",
      "2  2\n",
      "2  2\n",
      "4  4\n",
      "1  1\n",
      "5  8\n",
      "9  8\n",
      "8  8\n",
      "7  8\n",
      "2  3\n",
      "3  0\n",
      "0  0\n",
      "4  3\n",
      "4  4\n",
      "2  2\n",
      "4  4\n",
      "1  1\n",
      "9  9\n",
      "5  5\n",
      "7  7\n",
      "7  7\n",
      "2  2\n",
      "8  6\n",
      "2  2\n",
      "6  6\n",
      "8  8\n",
      "5  5\n",
      "7  7\n",
      "7  7\n",
      "9  9\n",
      "1  1\n",
      "8  6\n",
      "1  1\n",
      "8  8\n",
      "0  0\n",
      "3  3\n",
      "0  0\n",
      "1  1\n",
      "9  9\n",
      "9  9\n",
      "4  4\n",
      "1  1\n",
      "8  8\n",
      "2  2\n",
      "1  1\n",
      "2  6\n",
      "9  9\n",
      "7  7\n",
      "5  5\n",
      "9  9\n",
      "2  2\n",
      "6  6\n",
      "4  4\n",
      "1  1\n",
      "5  6\n",
      "8  5\n",
      "2  2\n",
      "9  9\n",
      "2  2\n",
      "0  0\n",
      "4  4\n",
      "0  0\n",
      "0  0\n",
      "2  2\n",
      "8  8\n",
      "4  6\n",
      "7  3\n",
      "1  1\n",
      "2  2\n",
      "4  4\n",
      "0  0\n",
      "2  2\n",
      "7  7\n",
      "4  8\n",
      "3  3\n",
      "3  3\n",
      "0  0\n",
      "0  0\n",
      "3  3\n",
      "1  1\n",
      "9  9\n",
      "6  6\n",
      "5  5\n",
      "2  6\n",
      "5  6\n",
      "9  8\n",
      "2  7\n",
      "9  9\n",
      "3  3\n",
      "0  3\n",
      "4  4\n",
      "2  2\n",
      "0  0\n",
      "7  7\n",
      "1  1\n",
      "1  1\n",
      "2  2\n",
      "1  1\n",
      "5  5\n",
      "3  3\n",
      "3  8\n",
      "9  9\n",
      "7  7\n",
      "8  8\n",
      "6  6\n",
      "5  3\n",
      "6  6\n",
      "1  1\n",
      "3  3\n",
      "8  8\n",
      "1  1\n",
      "0  0\n",
      "5  5\n",
      "1  1\n",
      "3  3\n",
      "1  1\n",
      "5  5\n",
      "5  0\n",
      "6  6\n",
      "1  1\n",
      "8  8\n",
      "5  5\n",
      "1  7\n",
      "7  7\n",
      "9  8\n",
      "4  4\n",
      "6  6\n",
      "2  2\n",
      "2  2\n",
      "5  5\n",
      "0  0\n",
      "6  6\n",
      "5  3\n",
      "6  6\n",
      "3  0\n",
      "7  7\n",
      "2  2\n",
      "0  0\n",
      "8  8\n",
      "8  8\n",
      "5  5\n",
      "4  9\n",
      "1  1\n",
      "1  1\n",
      "4  4\n",
      "0  0\n",
      "3  7\n",
      "3  3\n",
      "7  7\n",
      "6  6\n",
      "1  1\n",
      "6  6\n",
      "2  2\n",
      "1  1\n",
      "9  9\n",
      "2  2\n",
      "8  8\n",
      "6  6\n",
      "1  1\n",
      "9  4\n",
      "5  5\n",
      "2  2\n",
      "5  3\n",
      "4  4\n",
      "4  4\n",
      "2  8\n",
      "8  8\n",
      "3  3\n",
      "8  8\n",
      "2  2\n",
      "4  4\n",
      "5  6\n",
      "0  0\n",
      "3  3\n",
      "1  1\n",
      "7  7\n",
      "7  7\n",
      "5  8\n",
      "7  7\n",
      "9  9\n",
      "7  7\n",
      "1  1\n",
      "9  9\n",
      "2  2\n",
      "1  1\n",
      "4  4\n",
      "2  2\n",
      "9  9\n",
      "2  2\n",
      "0  0\n",
      "4  4\n",
      "9  9\n",
      "1  1\n",
      "4  4\n",
      "8  8\n",
      "1  1\n",
      "8  8\n",
      "4  4\n",
      "5  5\n",
      "9  9\n",
      "8  8\n",
      "8  8\n",
      "3  3\n",
      "7  7\n",
      "6  6\n",
      "0  0\n",
      "0  0\n",
      "3  3\n",
      "0  0\n",
      "2  7\n",
      "6  6\n",
      "6  6\n",
      "4  4\n",
      "9  8\n",
      "3  3\n",
      "3  3\n",
      "3  3\n",
      "2  2\n",
      "3  3\n",
      "9  9\n",
      "1  1\n",
      "2  2\n",
      "6  6\n",
      "8  8\n",
      "0  0\n",
      "5  9\n",
      "6  6\n",
      "6  6\n",
      "6  6\n",
      "3  7\n",
      "8  8\n",
      "8  8\n",
      "2  2\n",
      "7  7\n",
      "5  3\n",
      "8  8\n",
      "9  9\n",
      "6  6\n",
      "1  1\n",
      "8  8\n",
      "4  4\n",
      "1  1\n",
      "2  2\n",
      "5  0\n",
      "9  8\n",
      "1  1\n",
      "9  9\n",
      "7  7\n",
      "5  4\n",
      "4  4\n",
      "0  0\n",
      "8  8\n",
      "9  4\n",
      "9  9\n",
      "1  1\n",
      "0  0\n",
      "5  5\n",
      "2  2\n",
      "3  3\n",
      "7  7\n",
      "8  6\n",
      "9  9\n",
      "4  8\n",
      "0  7\n",
      "6  6\n",
      "3  3\n",
      "9  9\n",
      "5  5\n",
      "2  2\n",
      "1  7\n",
      "3  8\n",
      "1  1\n",
      "3  6\n",
      "6  5\n",
      "5  3\n",
      "7  7\n",
      "4  7\n",
      "2  2\n",
      "2  6\n",
      "6  6\n",
      "3  3\n",
      "2  4\n",
      "6  6\n",
      "5  5\n",
      "4  8\n",
      "8  8\n",
      "9  9\n",
      "7  9\n",
      "1  4\n",
      "3  3\n",
      "0  0\n",
      "3  3\n",
      "8  8\n",
      "3  2\n",
      "1  1\n",
      "9  9\n",
      "3  6\n",
      "4  9\n",
      "4  6\n",
      "6  6\n",
      "4  4\n",
      "2  2\n",
      "1  1\n",
      "8  8\n",
      "2  2\n",
      "5  8\n",
      "4  4\n",
      "8  8\n",
      "8  9\n",
      "4  4\n",
      "0  0\n",
      "0  0\n",
      "2  8\n",
      "3  3\n",
      "2  2\n",
      "7  7\n",
      "7  7\n",
      "0  8\n",
      "8  6\n",
      "7  7\n",
      "4  4\n",
      "4  4\n",
      "7  8\n",
      "9  9\n",
      "6  6\n",
      "9  9\n",
      "0  0\n",
      "9  9\n",
      "8  8\n",
      "0  0\n",
      "4  4\n",
      "6  6\n",
      "0  0\n",
      "6  6\n",
      "3  3\n",
      "5  5\n",
      "4  9\n",
      "8  8\n",
      "3  3\n",
      "3  3\n",
      "9  9\n",
      "3  3\n",
      "3  3\n",
      "3  8\n",
      "7  7\n",
      "8  8\n",
      "0  0\n",
      "8  8\n",
      "2  8\n",
      "1  1\n",
      "7  7\n",
      "0  0\n",
      "6  6\n",
      "5  0\n",
      "4  4\n",
      "3  3\n",
      "8  3\n",
      "0  0\n",
      "9  9\n",
      "6  6\n",
      "3  3\n",
      "8  8\n",
      "0  0\n",
      "9  9\n",
      "9  9\n",
      "6  6\n",
      "8  7\n",
      "6  6\n",
      "8  8\n",
      "5  5\n",
      "7  7\n",
      "8  3\n",
      "6  6\n",
      "0  0\n",
      "2  2\n",
      "4  8\n",
      "0  0\n",
      "2  2\n",
      "2  2\n",
      "3  3\n",
      "1  1\n",
      "9  9\n",
      "7  7\n",
      "5  3\n",
      "1  1\n",
      "0  0\n",
      "8  8\n",
      "4  4\n",
      "6  6\n",
      "2  1\n",
      "6  6\n",
      "7  7\n",
      "9  8\n",
      "3  9\n",
      "2  0\n",
      "9  9\n",
      "8  3\n",
      "2  0\n",
      "2  2\n",
      "9  9\n",
      "2  6\n",
      "7  7\n",
      "3  3\n",
      "5  5\n",
      "9  9\n",
      "1  1\n",
      "8  8\n",
      "0  0\n",
      "2  2\n",
      "0  0\n",
      "5  3\n",
      "2  6\n",
      "1  1\n",
      "3  3\n",
      "7  7\n",
      "6  6\n",
      "7  7\n",
      "1  1\n",
      "2  2\n",
      "5  8\n",
      "8  8\n",
      "0  0\n",
      "3  3\n",
      "7  7\n",
      "2  2\n",
      "4  4\n",
      "0  0\n",
      "9  9\n",
      "1  1\n",
      "8  8\n",
      "6  6\n",
      "7  7\n",
      "7  7\n",
      "4  4\n",
      "3  5\n",
      "4  4\n",
      "9  9\n",
      "1  1\n",
      "9  9\n",
      "5  3\n",
      "1  1\n",
      "7  7\n",
      "3  6\n",
      "9  9\n",
      "7  7\n",
      "6  6\n",
      "9  9\n",
      "1  1\n",
      "3  3\n",
      "7  2\n",
      "8  8\n",
      "3  3\n",
      "3  3\n",
      "6  6\n",
      "7  9\n",
      "2  2\n",
      "8  6\n",
      "5  5\n",
      "8  8\n",
      "5  8\n",
      "1  1\n",
      "1  1\n",
      "4  4\n",
      "4  4\n",
      "3  3\n",
      "1  1\n",
      "0  0\n",
      "7  7\n",
      "7  7\n",
      "0  0\n",
      "7  7\n",
      "9  9\n",
      "4  4\n",
      "4  4\n",
      "8  8\n",
      "5  5\n",
      "5  5\n",
      "4  7\n",
      "0  0\n",
      "8  8\n",
      "2  2\n",
      "1  1\n",
      "0  6\n",
      "8  8\n",
      "4  4\n",
      "5  4\n",
      "0  0\n",
      "4  4\n",
      "0  0\n",
      "6  6\n",
      "1  1\n",
      "7  5\n",
      "3  8\n",
      "2  2\n",
      "6  6\n",
      "7  7\n",
      "2  2\n",
      "6  6\n",
      "9  9\n",
      "3  3\n",
      "1  1\n",
      "4  4\n",
      "6  6\n",
      "2  2\n",
      "5  8\n",
      "4  9\n",
      "2  7\n",
      "0  0\n",
      "6  6\n",
      "2  2\n",
      "1  1\n",
      "7  7\n",
      "3  8\n",
      "4  9\n",
      "1  1\n",
      "0  0\n",
      "5  3\n",
      "4  4\n",
      "3  3\n",
      "1  1\n",
      "1  1\n",
      "7  7\n",
      "4  4\n",
      "9  9\n",
      "9  9\n",
      "4  9\n",
      "8  8\n",
      "4  4\n",
      "0  0\n",
      "2  2\n",
      "4  4\n",
      "5  8\n",
      "1  1\n",
      "1  1\n",
      "6  6\n",
      "4  4\n",
      "7  7\n",
      "1  1\n",
      "9  9\n",
      "4  4\n",
      "2  2\n",
      "4  4\n",
      "1  1\n",
      "5  6\n",
      "5  5\n",
      "3  3\n",
      "8  6\n",
      "3  3\n",
      "1  1\n",
      "4  4\n",
      "5  3\n",
      "6  6\n",
      "8  8\n",
      "9  9\n",
      "4  4\n",
      "1  1\n",
      "5  9\n",
      "3  3\n",
      "8  8\n",
      "0  0\n",
      "3  2\n",
      "2  2\n",
      "5  5\n",
      "1  1\n",
      "2  2\n",
      "8  3\n",
      "3  3\n",
      "4  4\n",
      "4  4\n",
      "0  0\n",
      "8  8\n",
      "8  8\n",
      "3  3\n",
      "3  3\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "5  8\n",
      "9  9\n",
      "6  6\n",
      "3  3\n",
      "2  2\n",
      "6  6\n",
      "1  1\n",
      "3  3\n",
      "6  6\n",
      "0  0\n",
      "7  7\n",
      "2  8\n",
      "1  1\n",
      "7  7\n",
      "1  1\n",
      "4  4\n",
      "2  2\n",
      "4  5\n",
      "2  2\n",
      "1  1\n",
      "7  7\n",
      "9  9\n",
      "6  6\n",
      "1  1\n",
      "1  1\n",
      "2  2\n",
      "4  4\n",
      "8  0\n",
      "1  1\n",
      "7  7\n",
      "7  7\n",
      "4  4\n",
      "8  8\n",
      "0  0\n",
      "7  7\n",
      "3  3\n",
      "1  1\n",
      "3  3\n",
      "1  1\n",
      "0  0\n",
      "7  7\n",
      "7  7\n",
      "0  0\n",
      "3  3\n",
      "5  5\n",
      "5  3\n",
      "2  2\n",
      "7  7\n",
      "6  6\n",
      "6  6\n",
      "9  9\n",
      "2  8\n",
      "8  8\n",
      "3  3\n",
      "5  8\n",
      "2  2\n",
      "2  2\n",
      "5  8\n",
      "6  6\n",
      "0  0\n",
      "8  8\n",
      "2  2\n",
      "9  9\n",
      "2  2\n",
      "8  3\n",
      "8  8\n",
      "8  8\n",
      "8  5\n",
      "7  7\n",
      "4  4\n",
      "9  9\n",
      "3  3\n",
      "0  0\n",
      "6  6\n",
      "6  6\n",
      "3  3\n",
      "2  2\n",
      "1  1\n",
      "3  3\n",
      "2  2\n",
      "2  2\n",
      "9  9\n",
      "3  8\n",
      "0  0\n",
      "0  0\n",
      "5  5\n",
      "7  7\n",
      "8  8\n",
      "1  6\n",
      "4  4\n",
      "4  4\n",
      "6  6\n",
      "0  0\n",
      "2  2\n",
      "9  9\n",
      "1  1\n",
      "4  4\n",
      "7  7\n",
      "4  4\n",
      "7  7\n",
      "3  3\n",
      "9  9\n",
      "8  8\n",
      "8  6\n",
      "4  4\n",
      "7  7\n",
      "1  1\n",
      "2  2\n",
      "1  1\n",
      "2  2\n",
      "2  2\n",
      "3  3\n",
      "2  2\n",
      "3  3\n",
      "2  0\n",
      "3  0\n",
      "9  9\n",
      "1  1\n",
      "7  7\n",
      "4  4\n",
      "0  0\n",
      "3  3\n",
      "5  5\n",
      "5  4\n",
      "8  8\n",
      "6  6\n",
      "3  3\n",
      "2  0\n",
      "6  6\n",
      "7  7\n",
      "6  6\n",
      "6  6\n",
      "3  3\n",
      "2  2\n",
      "7  7\n",
      "8  8\n",
      "1  1\n",
      "1  1\n",
      "7  7\n",
      "5  3\n",
      "6  6\n",
      "4  4\n",
      "9  9\n",
      "5  6\n",
      "1  2\n",
      "3  8\n",
      "3  3\n",
      "4  4\n",
      "7  7\n",
      "8  8\n",
      "9  9\n",
      "1  1\n",
      "1  1\n",
      "6  0\n",
      "9  9\n",
      "1  1\n",
      "4  4\n",
      "4  4\n",
      "5  5\n",
      "4  4\n",
      "0  0\n",
      "6  6\n",
      "2  2\n",
      "2  6\n",
      "3  3\n",
      "1  1\n",
      "5  5\n",
      "1  1\n",
      "2  2\n",
      "0  0\n",
      "3  8\n",
      "8  8\n",
      "1  1\n",
      "2  2\n",
      "6  6\n",
      "7  9\n",
      "1  1\n",
      "6  6\n",
      "2  2\n",
      "3  3\n",
      "9  9\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "2  2\n",
      "0  0\n",
      "8  0\n",
      "9  9\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "for i in range(len(predictions)):\n",
    "    x=get_index(predictions[i])\n",
    "    y.append(x)\n",
    "for i in range(len(y)):\n",
    "    print(actual[i],\"\",y[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
