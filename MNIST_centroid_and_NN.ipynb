{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d675d216",
   "metadata": {},
   "source": [
    "# Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623d02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c4542",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c24944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(x_train,y_train) , (x_test ,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015c35c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 1000\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[:10000,:,:]\n",
    "x_test = x_test[:1000,:,:]\n",
    "y_train = y_train[:10000]\n",
    "y_test  = y_test[:1000]\n",
    "\n",
    "print(len(x_train), len(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f5c8c",
   "metadata": {},
   "source": [
    "# showing a sample of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2977c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d180dc",
   "metadata": {},
   "source": [
    "# split the image into grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdd3b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockshaped(arr, nrows, ncols):\n",
    "    h, w = arr.shape\n",
    "    grid = (arr.reshape(h//nrows, nrows, -1, ncols)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, nrows, ncols))\n",
    "    return grid\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78149639",
   "metadata": {},
   "source": [
    "# get the centroid for each grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f08843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(grid):\n",
    "    Mx = 0\n",
    "    My = 0\n",
    "    mass = 0\n",
    "    for i in range(len(grid)):\n",
    "        for j in range(len(grid[i])):\n",
    "            if grid[i][j]:\n",
    "                Mx += j\n",
    "                My += i\n",
    "                mass += 1\n",
    "        if mass==0:\n",
    "            mass=1\n",
    "    point = (float(Mx)/mass , float(My)/mass)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55791f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e3c32",
   "metadata": {},
   "source": [
    "# Applying the functions on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ef8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b68e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic in x_train:\n",
    "    grid=blockshaped(pic,cols ,cols)\n",
    "    train_vector.append([centroid(x) for x in grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb9b3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector=np.array(train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b66341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vector=train_vector.reshape(10000,len(train_vector[0])*2,1)\n",
    "train_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793916e",
   "metadata": {},
   "source": [
    "# Applying the functions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61619fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15760da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic in x_test:\n",
    "    grid=blockshaped(pic, cols , cols)\n",
    "    test_vector.append([centroid(x) for x in grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "493ffb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector=np.array(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330301bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector=test_vector.reshape(1000,len(test_vector[0])*2,1)\n",
    "test_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849c6dc",
   "metadata": {},
   "source": [
    "# apply one hot encoder representation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcffc260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape=(10000, 32, 1)\n",
      "train_label shape=(10000, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "train_label = np.zeros((10000, 10,1))\n",
    "for col in range (10000):\n",
    "    val=y_train[col]\n",
    "    for row in range (10):\n",
    "        if (val==row):\n",
    "            train_label[col][row]=1\n",
    "\n",
    "print(\"train_data shape=\"+str(np.shape(train_vector)))\n",
    "print(\"train_label shape=\"+str(np.shape(train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb680e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data shape=(1000, 32, 1)\n",
      "test_label shape=(1000, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "test_label = np.zeros((1000, 10,1))\n",
    "for col in range (1000):\n",
    "    val=y_test[col]\n",
    "    for row in range (10):\n",
    "        if (val==row):\n",
    "            test_label[col,val]=1\n",
    "print(\"test_data shape=\"+str(np.shape(test_vector)))\n",
    "print(\"test_label shape=\"+str(np.shape(test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc779b",
   "metadata": {},
   "source": [
    "# apply NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d6fe68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(no_neurons_h1,no_neurons_h2,output_layer):\n",
    "    W1 = np.random.randn(no_neurons_h1, len(train_vector[0])) \n",
    "    W2 = np.random.randn(no_neurons_h2, len(W1)) \n",
    "    W3 = np.random.randn(output_layer, len(W2)) \n",
    "    return W1, W2,W3\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return  1/(1 + np.exp(-Z))\n",
    "\n",
    "def normalization(x):\n",
    "    sum=0\n",
    "    for i in range(len(x)):\n",
    "        sum+=x[i]\n",
    "    for i in range(len(x)):\n",
    "        x[i]=x[i]/sum\n",
    "    return x\n",
    "\n",
    "def MSE(actual,predicted):\n",
    "    sum = 0  \n",
    "    n = len(actual) \n",
    "    for i in range (0,n):  \n",
    "        difference = actual[i] - predicted[i]  \n",
    "        squared_difference = difference**2  \n",
    "        sum = sum + squared_difference  \n",
    "    MSE = sum/n  \n",
    "    return MSE\n",
    "def get_index(x):\n",
    "    index=0\n",
    "    max=x[0]\n",
    "    for i in range(10):\n",
    "        if max<x[i]:\n",
    "            max=x[i]\n",
    "            index=i\n",
    "    return index\n",
    "        \n",
    "def forward_prop(W1, W2, W3,X):\n",
    "    #hidden layer1\n",
    "    Z1=W1.dot(X)\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    #hidden layer2\n",
    "    Z2 = W2.dot(A1)\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    #output layer\n",
    "    Z3 = W3.dot(A2)\n",
    "    A3 = sigmoid(Z3)\n",
    "    A3=normalization(A3)\n",
    "    return Z1, A1, Z2, A2,Z3,A3\n",
    "\n",
    "def sigmoid_deriv(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2,Z3, A3, W1, W2,W3,alpha, X, train_label):\n",
    "    \n",
    "    #output layer\n",
    "    error=train_label-A3\n",
    "    dZ3 = error*sigmoid_deriv(Z3)\n",
    "    dW3 = alpha* dZ3.dot(A2.T)\n",
    "    \n",
    "    #hidden layer 2\n",
    "    dZ2 = W3.T.dot(dZ3) * sigmoid_deriv(Z2)\n",
    "    dW2 = alpha * dZ2.dot(A1.T)\n",
    "\n",
    "    #hidden layer 1\n",
    "    dZ1 = W2.T.dot(dZ2) * sigmoid_deriv(Z1)    \n",
    "    dW1 = alpha * dZ1.dot(X.T)\n",
    "    \n",
    "    return dW1,dW2,dW3\n",
    "\n",
    "def update_params(W1,  W2,W3 , dW1, dW2,dW3, alpha):\n",
    "    W1 = W1+dW1\n",
    "    W2 = W2+dW2\n",
    "    W3 = W3+dW3  \n",
    "    return W1,W2,W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32cd68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1,W2,W3):\n",
    "    _, _, _,_,_, A3 = forward_prop(W1,W2,W3, X)\n",
    "    return A3\n",
    "\n",
    "def get_accuracy(actual, predicted1):\n",
    "    correct = 0\n",
    "    predicted=[]\n",
    "    for i in range(len(predicted1)):\n",
    "        x=get_index(predicted1[i])\n",
    "        predicted.append(x)\n",
    "        \n",
    "    for i in range(len(predicted)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "def training_fit(X, Y, neurons_h1,neurons_h2,alpha,iterations):\n",
    "    W1, W2,W3 = init_params(neurons_h1,neurons_h2,10)\n",
    "    actual=[]\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        x=get_index(Y[i])\n",
    "        actual.append(x)\n",
    "    \n",
    "    for j in range(iterations):\n",
    "        print(\"Iteration: \",j)\n",
    "        predictions=[]\n",
    "        error=0\n",
    "        for i in range(len(X)):\n",
    "            Z1, A1, Z2, A2,Z3, A3 = forward_prop(W1,W2,W3, X[i])\n",
    "            error+=MSE(A3,Y[i])\n",
    "            dW1, dW2,dW3= backward_prop(Z1, A1, Z2, A2, Z3, A3,W1,W2,W3, alpha,X[i], Y[i])\n",
    "            W1, W2,W3 = update_params(W1, W2,W3,dW1,dW2,dW3, alpha)\n",
    "            predictions.append(make_predictions(X[i],W1, W2,W3))\n",
    "        print(\"Error: \",error/len(X))\n",
    "        print(\"Training Accuracy: \",get_accuracy(actual,predictions),\" %\")\n",
    "    return W1, W2,W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29643416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Error:  [0.09135724]\n",
      "Training Accuracy:  4.16  %\n",
      "Iteration:  1\n",
      "Error:  [0.08691576]\n",
      "Training Accuracy:  6.3100000000000005  %\n",
      "Iteration:  2\n",
      "Error:  [0.08478692]\n",
      "Training Accuracy:  7.6499999999999995  %\n",
      "Iteration:  3\n",
      "Error:  [0.08160976]\n",
      "Training Accuracy:  24.86  %\n",
      "Iteration:  4\n",
      "Error:  [0.07057293]\n",
      "Training Accuracy:  57.11000000000001  %\n",
      "Iteration:  5\n",
      "Error:  [0.06377292]\n",
      "Training Accuracy:  63.690000000000005  %\n",
      "Iteration:  6\n",
      "Error:  [0.05904977]\n",
      "Training Accuracy:  66.9  %\n",
      "Iteration:  7\n",
      "Error:  [0.05513794]\n",
      "Training Accuracy:  69.3  %\n",
      "Iteration:  8\n",
      "Error:  [0.05180897]\n",
      "Training Accuracy:  71.3  %\n",
      "Iteration:  9\n",
      "Error:  [0.04889089]\n",
      "Training Accuracy:  73.49  %\n",
      "Iteration:  10\n",
      "Error:  [0.04621846]\n",
      "Training Accuracy:  75.27000000000001  %\n",
      "Iteration:  11\n",
      "Error:  [0.04371408]\n",
      "Training Accuracy:  76.97  %\n",
      "Iteration:  12\n",
      "Error:  [0.04147694]\n",
      "Training Accuracy:  78.0  %\n",
      "Iteration:  13\n",
      "Error:  [0.03953492]\n",
      "Training Accuracy:  79.33  %\n",
      "Iteration:  14\n",
      "Error:  [0.03782601]\n",
      "Training Accuracy:  80.34  %\n",
      "Iteration:  15\n",
      "Error:  [0.03629535]\n",
      "Training Accuracy:  81.17  %\n",
      "Iteration:  16\n",
      "Error:  [0.03491297]\n",
      "Training Accuracy:  81.77  %\n",
      "Iteration:  17\n",
      "Error:  [0.0336646]\n",
      "Training Accuracy:  82.44  %\n",
      "Iteration:  18\n",
      "Error:  [0.03253876]\n",
      "Training Accuracy:  83.07  %\n",
      "Iteration:  19\n",
      "Error:  [0.03151959]\n",
      "Training Accuracy:  83.42  %\n",
      "Iteration:  20\n",
      "Error:  [0.03059289]\n",
      "Training Accuracy:  83.89  %\n",
      "Iteration:  21\n",
      "Error:  [0.02975008]\n",
      "Training Accuracy:  84.23  %\n",
      "Iteration:  22\n",
      "Error:  [0.02898349]\n",
      "Training Accuracy:  84.57000000000001  %\n",
      "Iteration:  23\n",
      "Error:  [0.02828634]\n",
      "Training Accuracy:  84.98  %\n",
      "Iteration:  24\n",
      "Error:  [0.02765211]\n",
      "Training Accuracy:  85.24000000000001  %\n",
      "Iteration:  25\n",
      "Error:  [0.02707362]\n",
      "Training Accuracy:  85.46000000000001  %\n",
      "Iteration:  26\n",
      "Error:  [0.02654388]\n",
      "Training Accuracy:  85.76  %\n",
      "Iteration:  27\n",
      "Error:  [0.02605724]\n",
      "Training Accuracy:  86.04  %\n",
      "Iteration:  28\n",
      "Error:  [0.02560955]\n",
      "Training Accuracy:  86.22  %\n",
      "Iteration:  29\n",
      "Error:  [0.02519732]\n",
      "Training Accuracy:  86.42999999999999  %\n",
      "Iteration:  30\n",
      "Error:  [0.02481697]\n",
      "Training Accuracy:  86.59  %\n",
      "Iteration:  31\n",
      "Error:  [0.02446519]\n",
      "Training Accuracy:  86.75  %\n",
      "Iteration:  32\n",
      "Error:  [0.02413917]\n",
      "Training Accuracy:  86.9  %\n",
      "Iteration:  33\n",
      "Error:  [0.02383639]\n",
      "Training Accuracy:  86.98  %\n",
      "Iteration:  34\n",
      "Error:  [0.0235544]\n",
      "Training Accuracy:  87.19  %\n",
      "Iteration:  35\n",
      "Error:  [0.02329084]\n",
      "Training Accuracy:  87.26  %\n",
      "Iteration:  36\n",
      "Error:  [0.02304356]\n",
      "Training Accuracy:  87.35000000000001  %\n",
      "Iteration:  37\n",
      "Error:  [0.02281069]\n",
      "Training Accuracy:  87.48  %\n",
      "Iteration:  38\n",
      "Error:  [0.02259067]\n",
      "Training Accuracy:  87.55  %\n",
      "Iteration:  39\n",
      "Error:  [0.02238216]\n",
      "Training Accuracy:  87.66000000000001  %\n",
      "Iteration:  40\n",
      "Error:  [0.02218402]\n",
      "Training Accuracy:  87.75  %\n",
      "Iteration:  41\n",
      "Error:  [0.02199523]\n",
      "Training Accuracy:  87.81  %\n",
      "Iteration:  42\n",
      "Error:  [0.02181489]\n",
      "Training Accuracy:  87.87  %\n",
      "Iteration:  43\n",
      "Error:  [0.02164219]\n",
      "Training Accuracy:  87.9  %\n",
      "Iteration:  44\n",
      "Error:  [0.02147647]\n",
      "Training Accuracy:  87.94999999999999  %\n",
      "Iteration:  45\n",
      "Error:  [0.02131721]\n",
      "Training Accuracy:  88.03  %\n",
      "Iteration:  46\n",
      "Error:  [0.02116399]\n",
      "Training Accuracy:  88.12  %\n",
      "Iteration:  47\n",
      "Error:  [0.02101644]\n",
      "Training Accuracy:  88.21  %\n",
      "Iteration:  48\n",
      "Error:  [0.02087419]\n",
      "Training Accuracy:  88.28  %\n",
      "Iteration:  49\n",
      "Error:  [0.02073687]\n",
      "Training Accuracy:  88.33  %\n",
      "Iteration:  50\n",
      "Error:  [0.0206041]\n",
      "Training Accuracy:  88.37  %\n",
      "Iteration:  51\n",
      "Error:  [0.02047553]\n",
      "Training Accuracy:  88.39  %\n",
      "Iteration:  52\n",
      "Error:  [0.02035103]\n",
      "Training Accuracy:  88.48  %\n",
      "Iteration:  53\n",
      "Error:  [0.02023064]\n",
      "Training Accuracy:  88.53999999999999  %\n",
      "Iteration:  54\n",
      "Error:  [0.02011441]\n",
      "Training Accuracy:  88.58  %\n",
      "Iteration:  55\n",
      "Error:  [0.02000229]\n",
      "Training Accuracy:  88.67  %\n",
      "Iteration:  56\n",
      "Error:  [0.01989418]\n",
      "Training Accuracy:  88.69  %\n",
      "Iteration:  57\n",
      "Error:  [0.01978991]\n",
      "Training Accuracy:  88.75999999999999  %\n",
      "Iteration:  58\n",
      "Error:  [0.01968936]\n",
      "Training Accuracy:  88.81  %\n",
      "Iteration:  59\n",
      "Error:  [0.01959238]\n",
      "Training Accuracy:  88.88000000000001  %\n",
      "Iteration:  60\n",
      "Error:  [0.01949882]\n",
      "Training Accuracy:  88.97  %\n",
      "Iteration:  61\n",
      "Error:  [0.01940849]\n",
      "Training Accuracy:  89.0  %\n",
      "Iteration:  62\n",
      "Error:  [0.01932116]\n",
      "Training Accuracy:  89.0  %\n",
      "Iteration:  63\n",
      "Error:  [0.01923659]\n",
      "Training Accuracy:  89.03999999999999  %\n",
      "Iteration:  64\n",
      "Error:  [0.01915455]\n",
      "Training Accuracy:  89.17  %\n",
      "Iteration:  65\n",
      "Error:  [0.01907482]\n",
      "Training Accuracy:  89.22  %\n",
      "Iteration:  66\n",
      "Error:  [0.01899726]\n",
      "Training Accuracy:  89.24  %\n",
      "Iteration:  67\n",
      "Error:  [0.01892175]\n",
      "Training Accuracy:  89.3  %\n",
      "Iteration:  68\n",
      "Error:  [0.01884818]\n",
      "Training Accuracy:  89.3  %\n",
      "Iteration:  69\n",
      "Error:  [0.01877647]\n",
      "Training Accuracy:  89.35  %\n",
      "Iteration:  70\n",
      "Error:  [0.01870651]\n",
      "Training Accuracy:  89.36  %\n",
      "Iteration:  71\n",
      "Error:  [0.01863823]\n",
      "Training Accuracy:  89.4  %\n",
      "Iteration:  72\n",
      "Error:  [0.01857154]\n",
      "Training Accuracy:  89.38000000000001  %\n",
      "Iteration:  73\n",
      "Error:  [0.01850638]\n",
      "Training Accuracy:  89.42999999999999  %\n",
      "Iteration:  74\n",
      "Error:  [0.01844269]\n",
      "Training Accuracy:  89.48  %\n",
      "Iteration:  75\n",
      "Error:  [0.01838042]\n",
      "Training Accuracy:  89.57000000000001  %\n",
      "Iteration:  76\n",
      "Error:  [0.01831953]\n",
      "Training Accuracy:  89.61  %\n",
      "Iteration:  77\n",
      "Error:  [0.01825998]\n",
      "Training Accuracy:  89.64999999999999  %\n",
      "Iteration:  78\n",
      "Error:  [0.01820173]\n",
      "Training Accuracy:  89.66  %\n",
      "Iteration:  79\n",
      "Error:  [0.01814475]\n",
      "Training Accuracy:  89.66  %\n",
      "Iteration:  80\n",
      "Error:  [0.018089]\n",
      "Training Accuracy:  89.73  %\n",
      "Iteration:  81\n",
      "Error:  [0.01803445]\n",
      "Training Accuracy:  89.78  %\n",
      "Iteration:  82\n",
      "Error:  [0.01798105]\n",
      "Training Accuracy:  89.79  %\n",
      "Iteration:  83\n",
      "Error:  [0.01792876]\n",
      "Training Accuracy:  89.81  %\n",
      "Iteration:  84\n",
      "Error:  [0.01787753]\n",
      "Training Accuracy:  89.83  %\n",
      "Iteration:  85\n",
      "Error:  [0.01782733]\n",
      "Training Accuracy:  89.83  %\n",
      "Iteration:  86\n",
      "Error:  [0.01777813]\n",
      "Training Accuracy:  89.85  %\n",
      "Iteration:  87\n",
      "Error:  [0.01772988]\n",
      "Training Accuracy:  89.85  %\n",
      "Iteration:  88\n",
      "Error:  [0.01768257]\n",
      "Training Accuracy:  89.88000000000001  %\n",
      "Iteration:  89\n",
      "Error:  [0.01763619]\n",
      "Training Accuracy:  89.87  %\n",
      "Iteration:  90\n",
      "Error:  [0.01759072]\n",
      "Training Accuracy:  89.86  %\n",
      "Iteration:  91\n",
      "Error:  [0.01754616]\n",
      "Training Accuracy:  89.91  %\n",
      "Iteration:  92\n",
      "Error:  [0.01750252]\n",
      "Training Accuracy:  89.92999999999999  %\n",
      "Iteration:  93\n",
      "Error:  [0.01745978]\n",
      "Training Accuracy:  89.98  %\n",
      "Iteration:  94\n",
      "Error:  [0.01741796]\n",
      "Training Accuracy:  89.94  %\n",
      "Iteration:  95\n",
      "Error:  [0.01737705]\n",
      "Training Accuracy:  89.96  %\n",
      "Iteration:  96\n",
      "Error:  [0.01733702]\n",
      "Training Accuracy:  90.02  %\n",
      "Iteration:  97\n",
      "Error:  [0.01729787]\n",
      "Training Accuracy:  90.08  %\n",
      "Iteration:  98\n",
      "Error:  [0.01725956]\n",
      "Training Accuracy:  90.13  %\n",
      "Iteration:  99\n",
      "Error:  [0.01722204]\n",
      "Training Accuracy:  90.09  %\n"
     ]
    }
   ],
   "source": [
    "X_train=train_vector[:10000,:]\n",
    "Y_train=train_label[:10000,:]\n",
    "X_test=test_vector[:1000,:]\n",
    "Y_test=test_label[:1000,:]\n",
    "neurons_h1=45\n",
    "neurons_h2=24\n",
    "weight1,weight2,weight3= training_fit(X_train,Y_train,neurons_h1,neurons_h2,0.01,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb724ab",
   "metadata": {},
   "source": [
    "# testing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa5b97ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  83.8  %\n"
     ]
    }
   ],
   "source": [
    "actual=[]\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    x=get_index(Y_test[i])\n",
    "    actual.append(x)\n",
    "    \n",
    "predictions=[]\n",
    "for i in range(len(X_test)):\n",
    "    A3=make_predictions(X_test[i], weight1,weight2,weight3)\n",
    "    predictions.append(A3)\n",
    "\n",
    "print(\"Test Accuracy: \",get_accuracy(actual,predictions),\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84897c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  7\n",
      "2  2\n",
      "1  1\n",
      "0  0\n",
      "4  4\n",
      "1  1\n",
      "4  4\n",
      "9  4\n",
      "5  5\n",
      "9  9\n",
      "0  0\n",
      "6  6\n",
      "9  9\n",
      "0  0\n",
      "1  1\n",
      "5  6\n",
      "9  9\n",
      "7  7\n",
      "3  6\n",
      "4  4\n",
      "9  9\n",
      "6  6\n",
      "6  6\n",
      "5  5\n",
      "4  4\n",
      "0  0\n",
      "7  7\n",
      "4  4\n",
      "0  0\n",
      "1  1\n",
      "3  3\n",
      "1  1\n",
      "3  3\n",
      "4  4\n",
      "7  7\n",
      "2  2\n",
      "7  7\n",
      "1  1\n",
      "2  2\n",
      "1  1\n",
      "1  1\n",
      "7  7\n",
      "4  4\n",
      "2  2\n",
      "3  3\n",
      "5  8\n",
      "1  1\n",
      "2  2\n",
      "4  4\n",
      "4  4\n",
      "6  6\n",
      "3  3\n",
      "5  5\n",
      "5  5\n",
      "6  6\n",
      "0  0\n",
      "4  4\n",
      "1  1\n",
      "9  9\n",
      "5  5\n",
      "7  7\n",
      "8  8\n",
      "9  9\n",
      "3  3\n",
      "7  7\n",
      "4  4\n",
      "6  6\n",
      "4  4\n",
      "3  3\n",
      "0  0\n",
      "7  7\n",
      "0  0\n",
      "2  2\n",
      "9  7\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "2  2\n",
      "9  1\n",
      "7  7\n",
      "7  9\n",
      "6  6\n",
      "2  2\n",
      "7  7\n",
      "8  5\n",
      "4  4\n",
      "7  7\n",
      "3  3\n",
      "6  6\n",
      "1  1\n",
      "3  3\n",
      "6  6\n",
      "9  9\n",
      "3  3\n",
      "1  1\n",
      "4  4\n",
      "1  4\n",
      "7  4\n",
      "6  6\n",
      "9  9\n",
      "6  6\n",
      "0  0\n",
      "5  5\n",
      "4  4\n",
      "9  9\n",
      "9  9\n",
      "2  2\n",
      "1  1\n",
      "9  9\n",
      "4  9\n",
      "8  3\n",
      "7  7\n",
      "3  3\n",
      "9  9\n",
      "7  7\n",
      "4  4\n",
      "4  4\n",
      "4  4\n",
      "9  9\n",
      "2  8\n",
      "5  3\n",
      "4  4\n",
      "7  5\n",
      "6  6\n",
      "7  8\n",
      "9  9\n",
      "0  0\n",
      "5  5\n",
      "8  8\n",
      "5  5\n",
      "6  6\n",
      "6  6\n",
      "5  5\n",
      "7  7\n",
      "8  8\n",
      "1  1\n",
      "0  0\n",
      "1  1\n",
      "6  6\n",
      "4  4\n",
      "6  6\n",
      "7  7\n",
      "3  3\n",
      "1  1\n",
      "7  7\n",
      "1  1\n",
      "8  8\n",
      "2  2\n",
      "0  0\n",
      "2  2\n",
      "9  9\n",
      "9  9\n",
      "5  5\n",
      "5  0\n",
      "1  1\n",
      "5  5\n",
      "6  6\n",
      "0  0\n",
      "3  3\n",
      "4  3\n",
      "4  8\n",
      "6  6\n",
      "5  5\n",
      "4  4\n",
      "6  6\n",
      "5  5\n",
      "4  4\n",
      "5  5\n",
      "1  1\n",
      "4  4\n",
      "4  4\n",
      "7  3\n",
      "2  2\n",
      "3  3\n",
      "2  2\n",
      "7  7\n",
      "1  1\n",
      "8  8\n",
      "1  1\n",
      "8  8\n",
      "1  1\n",
      "8  8\n",
      "5  5\n",
      "0  0\n",
      "8  8\n",
      "9  9\n",
      "2  2\n",
      "5  3\n",
      "0  0\n",
      "1  1\n",
      "1  1\n",
      "1  1\n",
      "0  0\n",
      "9  3\n",
      "0  0\n",
      "3  7\n",
      "1  1\n",
      "6  6\n",
      "4  4\n",
      "2  3\n",
      "3  3\n",
      "6  6\n",
      "1  1\n",
      "1  1\n",
      "1  1\n",
      "3  3\n",
      "9  4\n",
      "5  5\n",
      "2  2\n",
      "9  9\n",
      "4  4\n",
      "5  5\n",
      "9  9\n",
      "3  3\n",
      "9  9\n",
      "0  0\n",
      "3  3\n",
      "6  6\n",
      "5  5\n",
      "5  5\n",
      "7  7\n",
      "2  3\n",
      "2  3\n",
      "7  7\n",
      "1  1\n",
      "2  2\n",
      "8  8\n",
      "4  9\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "3  3\n",
      "8  8\n",
      "8  8\n",
      "7  7\n",
      "9  7\n",
      "2  2\n",
      "2  2\n",
      "4  4\n",
      "1  1\n",
      "5  5\n",
      "9  8\n",
      "8  8\n",
      "7  7\n",
      "2  2\n",
      "3  7\n",
      "0  0\n",
      "4  6\n",
      "4  4\n",
      "2  2\n",
      "4  4\n",
      "1  1\n",
      "9  9\n",
      "5  5\n",
      "7  7\n",
      "7  7\n",
      "2  2\n",
      "8  3\n",
      "2  2\n",
      "6  0\n",
      "8  8\n",
      "5  5\n",
      "7  7\n",
      "7  7\n",
      "9  9\n",
      "1  1\n",
      "8  0\n",
      "1  1\n",
      "8  8\n",
      "0  0\n",
      "3  3\n",
      "0  0\n",
      "1  1\n",
      "9  9\n",
      "9  9\n",
      "4  4\n",
      "1  1\n",
      "8  8\n",
      "2  2\n",
      "1  1\n",
      "2  2\n",
      "9  9\n",
      "7  7\n",
      "5  5\n",
      "9  9\n",
      "2  2\n",
      "6  6\n",
      "4  4\n",
      "1  1\n",
      "5  6\n",
      "8  6\n",
      "2  2\n",
      "9  9\n",
      "2  2\n",
      "0  0\n",
      "4  4\n",
      "0  0\n",
      "0  0\n",
      "2  2\n",
      "8  8\n",
      "4  6\n",
      "7  3\n",
      "1  1\n",
      "2  2\n",
      "4  4\n",
      "0  0\n",
      "2  2\n",
      "7  9\n",
      "4  8\n",
      "3  3\n",
      "3  3\n",
      "0  0\n",
      "0  0\n",
      "3  3\n",
      "1  1\n",
      "9  9\n",
      "6  6\n",
      "5  5\n",
      "2  3\n",
      "5  6\n",
      "9  1\n",
      "2  7\n",
      "9  9\n",
      "3  3\n",
      "0  3\n",
      "4  7\n",
      "2  2\n",
      "0  0\n",
      "7  7\n",
      "1  1\n",
      "1  1\n",
      "2  2\n",
      "1  1\n",
      "5  5\n",
      "3  3\n",
      "3  8\n",
      "9  9\n",
      "7  7\n",
      "8  8\n",
      "6  6\n",
      "5  3\n",
      "6  6\n",
      "1  1\n",
      "3  3\n",
      "8  5\n",
      "1  1\n",
      "0  3\n",
      "5  5\n",
      "1  1\n",
      "3  3\n",
      "1  1\n",
      "5  5\n",
      "5  3\n",
      "6  0\n",
      "1  1\n",
      "8  8\n",
      "5  5\n",
      "1  1\n",
      "7  4\n",
      "9  9\n",
      "4  4\n",
      "6  6\n",
      "2  7\n",
      "2  6\n",
      "5  5\n",
      "0  0\n",
      "6  6\n",
      "5  3\n",
      "6  6\n",
      "3  3\n",
      "7  7\n",
      "2  2\n",
      "0  0\n",
      "8  8\n",
      "8  8\n",
      "5  5\n",
      "4  9\n",
      "1  1\n",
      "1  1\n",
      "4  4\n",
      "0  0\n",
      "3  6\n",
      "3  3\n",
      "7  7\n",
      "6  6\n",
      "1  1\n",
      "6  3\n",
      "2  2\n",
      "1  1\n",
      "9  9\n",
      "2  2\n",
      "8  8\n",
      "6  6\n",
      "1  1\n",
      "9  9\n",
      "5  5\n",
      "2  2\n",
      "5  3\n",
      "4  4\n",
      "4  4\n",
      "2  2\n",
      "8  8\n",
      "3  3\n",
      "8  9\n",
      "2  2\n",
      "4  4\n",
      "5  8\n",
      "0  0\n",
      "3  3\n",
      "1  1\n",
      "7  7\n",
      "7  7\n",
      "5  5\n",
      "7  7\n",
      "9  9\n",
      "7  7\n",
      "1  1\n",
      "9  9\n",
      "2  2\n",
      "1  1\n",
      "4  4\n",
      "2  2\n",
      "9  9\n",
      "2  2\n",
      "0  0\n",
      "4  4\n",
      "9  9\n",
      "1  1\n",
      "4  4\n",
      "8  8\n",
      "1  1\n",
      "8  8\n",
      "4  1\n",
      "5  5\n",
      "9  9\n",
      "8  8\n",
      "8  8\n",
      "3  3\n",
      "7  7\n",
      "6  6\n",
      "0  0\n",
      "0  0\n",
      "3  3\n",
      "0  8\n",
      "2  2\n",
      "6  6\n",
      "6  6\n",
      "4  4\n",
      "9  8\n",
      "3  3\n",
      "3  3\n",
      "3  3\n",
      "2  2\n",
      "3  2\n",
      "9  9\n",
      "1  1\n",
      "2  2\n",
      "6  6\n",
      "8  8\n",
      "0  0\n",
      "5  9\n",
      "6  6\n",
      "6  6\n",
      "6  6\n",
      "3  3\n",
      "8  8\n",
      "8  8\n",
      "2  2\n",
      "7  2\n",
      "5  3\n",
      "8  8\n",
      "9  9\n",
      "6  6\n",
      "1  1\n",
      "8  8\n",
      "4  4\n",
      "1  1\n",
      "2  2\n",
      "5  3\n",
      "9  3\n",
      "1  1\n",
      "9  9\n",
      "7  7\n",
      "5  8\n",
      "4  4\n",
      "0  0\n",
      "8  8\n",
      "9  9\n",
      "9  9\n",
      "1  1\n",
      "0  0\n",
      "5  3\n",
      "2  2\n",
      "3  3\n",
      "7  7\n",
      "8  3\n",
      "9  9\n",
      "4  4\n",
      "0  8\n",
      "6  6\n",
      "3  3\n",
      "9  9\n",
      "5  3\n",
      "2  2\n",
      "1  1\n",
      "3  8\n",
      "1  1\n",
      "3  3\n",
      "6  5\n",
      "5  3\n",
      "7  7\n",
      "4  4\n",
      "2  2\n",
      "2  2\n",
      "6  6\n",
      "3  3\n",
      "2  6\n",
      "6  6\n",
      "5  5\n",
      "4  4\n",
      "8  8\n",
      "9  9\n",
      "7  9\n",
      "1  1\n",
      "3  3\n",
      "0  0\n",
      "3  3\n",
      "8  8\n",
      "3  2\n",
      "1  1\n",
      "9  9\n",
      "3  6\n",
      "4  9\n",
      "4  4\n",
      "6  6\n",
      "4  4\n",
      "2  2\n",
      "1  1\n",
      "8  8\n",
      "2  2\n",
      "5  5\n",
      "4  4\n",
      "8  8\n",
      "8  9\n",
      "4  4\n",
      "0  0\n",
      "0  0\n",
      "2  8\n",
      "3  3\n",
      "2  2\n",
      "7  7\n",
      "7  7\n",
      "0  8\n",
      "8  8\n",
      "7  7\n",
      "4  4\n",
      "4  4\n",
      "7  7\n",
      "9  9\n",
      "6  6\n",
      "9  9\n",
      "0  0\n",
      "9  9\n",
      "8  8\n",
      "0  0\n",
      "4  4\n",
      "6  6\n",
      "0  0\n",
      "6  6\n",
      "3  5\n",
      "5  5\n",
      "4  4\n",
      "8  8\n",
      "3  3\n",
      "3  3\n",
      "9  9\n",
      "3  3\n",
      "3  3\n",
      "3  8\n",
      "7  7\n",
      "8  8\n",
      "0  0\n",
      "8  8\n",
      "2  6\n",
      "1  1\n",
      "7  7\n",
      "0  0\n",
      "6  6\n",
      "5  5\n",
      "4  4\n",
      "3  3\n",
      "8  3\n",
      "0  0\n",
      "9  9\n",
      "6  6\n",
      "3  3\n",
      "8  8\n",
      "0  0\n",
      "9  9\n",
      "9  9\n",
      "6  6\n",
      "8  8\n",
      "6  6\n",
      "8  8\n",
      "5  3\n",
      "7  9\n",
      "8  3\n",
      "6  6\n",
      "0  0\n",
      "2  2\n",
      "4  0\n",
      "0  0\n",
      "2  2\n",
      "2  8\n",
      "3  3\n",
      "1  1\n",
      "9  9\n",
      "7  6\n",
      "5  3\n",
      "1  3\n",
      "0  0\n",
      "8  8\n",
      "4  4\n",
      "6  6\n",
      "2  1\n",
      "6  6\n",
      "7  7\n",
      "9  9\n",
      "3  9\n",
      "2  0\n",
      "9  9\n",
      "8  8\n",
      "2  2\n",
      "2  2\n",
      "9  9\n",
      "2  3\n",
      "7  7\n",
      "3  3\n",
      "5  5\n",
      "9  9\n",
      "1  1\n",
      "8  8\n",
      "0  0\n",
      "2  2\n",
      "0  0\n",
      "5  3\n",
      "2  6\n",
      "1  1\n",
      "3  3\n",
      "7  7\n",
      "6  6\n",
      "7  7\n",
      "1  1\n",
      "2  2\n",
      "5  0\n",
      "8  8\n",
      "0  0\n",
      "3  3\n",
      "7  7\n",
      "2  8\n",
      "4  4\n",
      "0  3\n",
      "9  9\n",
      "1  1\n",
      "8  8\n",
      "6  6\n",
      "7  7\n",
      "7  7\n",
      "4  4\n",
      "3  5\n",
      "4  8\n",
      "9  9\n",
      "1  1\n",
      "9  4\n",
      "5  3\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "9  9\n",
      "7  7\n",
      "6  6\n",
      "9  9\n",
      "1  1\n",
      "3  3\n",
      "7  3\n",
      "8  8\n",
      "3  3\n",
      "3  3\n",
      "6  6\n",
      "7  3\n",
      "2  2\n",
      "8  4\n",
      "5  5\n",
      "8  8\n",
      "5  5\n",
      "1  1\n",
      "1  1\n",
      "4  4\n",
      "4  4\n",
      "3  3\n",
      "1  1\n",
      "0  0\n",
      "7  7\n",
      "7  7\n",
      "0  0\n",
      "7  7\n",
      "9  9\n",
      "4  8\n",
      "4  4\n",
      "8  8\n",
      "5  3\n",
      "5  5\n",
      "4  3\n",
      "0  0\n",
      "8  8\n",
      "2  2\n",
      "1  1\n",
      "0  0\n",
      "8  8\n",
      "4  4\n",
      "5  8\n",
      "0  0\n",
      "4  4\n",
      "0  0\n",
      "6  6\n",
      "1  1\n",
      "7  5\n",
      "3  3\n",
      "2  8\n",
      "6  6\n",
      "7  7\n",
      "2  2\n",
      "6  6\n",
      "9  9\n",
      "3  3\n",
      "1  1\n",
      "4  4\n",
      "6  6\n",
      "2  2\n",
      "5  3\n",
      "4  9\n",
      "2  7\n",
      "0  0\n",
      "6  6\n",
      "2  2\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "4  9\n",
      "1  1\n",
      "0  0\n",
      "5  3\n",
      "4  4\n",
      "3  3\n",
      "1  1\n",
      "1  1\n",
      "7  7\n",
      "4  4\n",
      "9  9\n",
      "9  9\n",
      "4  9\n",
      "8  8\n",
      "4  4\n",
      "0  0\n",
      "2  2\n",
      "4  4\n",
      "5  8\n",
      "1  1\n",
      "1  1\n",
      "6  6\n",
      "4  8\n",
      "7  7\n",
      "1  1\n",
      "9  9\n",
      "4  9\n",
      "2  2\n",
      "4  4\n",
      "1  1\n",
      "5  5\n",
      "5  5\n",
      "3  3\n",
      "8  3\n",
      "3  3\n",
      "1  1\n",
      "4  4\n",
      "5  3\n",
      "6  6\n",
      "8  8\n",
      "9  9\n",
      "4  4\n",
      "1  1\n",
      "5  4\n",
      "3  3\n",
      "8  8\n",
      "0  0\n",
      "3  3\n",
      "2  2\n",
      "5  5\n",
      "1  1\n",
      "2  2\n",
      "8  3\n",
      "3  3\n",
      "4  4\n",
      "4  4\n",
      "0  0\n",
      "8  8\n",
      "8  8\n",
      "3  3\n",
      "3  3\n",
      "1  1\n",
      "7  7\n",
      "3  3\n",
      "5  5\n",
      "9  9\n",
      "6  6\n",
      "3  3\n",
      "2  2\n",
      "6  0\n",
      "1  1\n",
      "3  3\n",
      "6  6\n",
      "0  0\n",
      "7  7\n",
      "2  2\n",
      "1  1\n",
      "7  7\n",
      "1  1\n",
      "4  4\n",
      "2  2\n",
      "4  8\n",
      "2  2\n",
      "1  1\n",
      "7  9\n",
      "9  9\n",
      "6  6\n",
      "1  1\n",
      "1  1\n",
      "2  2\n",
      "4  4\n",
      "8  0\n",
      "1  1\n",
      "7  7\n",
      "7  7\n",
      "4  4\n",
      "8  3\n",
      "0  0\n",
      "7  7\n",
      "3  3\n",
      "1  1\n",
      "3  3\n",
      "1  1\n",
      "0  0\n",
      "7  7\n",
      "7  7\n",
      "0  0\n",
      "3  3\n",
      "5  8\n",
      "5  3\n",
      "2  2\n",
      "7  7\n",
      "6  6\n",
      "6  6\n",
      "9  9\n",
      "2  6\n",
      "8  8\n",
      "3  3\n",
      "5  8\n",
      "2  2\n",
      "2  2\n",
      "5  5\n",
      "6  6\n",
      "0  0\n",
      "8  8\n",
      "2  2\n",
      "9  9\n",
      "2  2\n",
      "8  3\n",
      "8  6\n",
      "8  8\n",
      "8  8\n",
      "7  7\n",
      "4  9\n",
      "9  9\n",
      "3  3\n",
      "0  0\n",
      "6  6\n",
      "6  6\n",
      "3  3\n",
      "2  2\n",
      "1  1\n",
      "3  3\n",
      "2  2\n",
      "2  2\n",
      "9  9\n",
      "3  3\n",
      "0  3\n",
      "0  0\n",
      "5  5\n",
      "7  7\n",
      "8  8\n",
      "1  3\n",
      "4  4\n",
      "4  4\n",
      "6  6\n",
      "0  0\n",
      "2  2\n",
      "9  9\n",
      "1  1\n",
      "4  4\n",
      "7  7\n",
      "4  4\n",
      "7  7\n",
      "3  3\n",
      "9  9\n",
      "8  8\n",
      "8  3\n",
      "4  4\n",
      "7  7\n",
      "1  1\n",
      "2  2\n",
      "1  1\n",
      "2  2\n",
      "2  2\n",
      "3  3\n",
      "2  7\n",
      "3  3\n",
      "2  8\n",
      "3  3\n",
      "9  9\n",
      "1  1\n",
      "7  7\n",
      "4  4\n",
      "0  0\n",
      "3  3\n",
      "5  5\n",
      "5  5\n",
      "8  8\n",
      "6  6\n",
      "3  3\n",
      "2  7\n",
      "6  3\n",
      "7  7\n",
      "6  6\n",
      "6  6\n",
      "3  3\n",
      "2  2\n",
      "7  7\n",
      "8  8\n",
      "1  1\n",
      "1  1\n",
      "7  7\n",
      "5  3\n",
      "6  6\n",
      "4  4\n",
      "9  9\n",
      "5  3\n",
      "1  2\n",
      "3  3\n",
      "3  3\n",
      "4  9\n",
      "7  7\n",
      "8  8\n",
      "9  9\n",
      "1  1\n",
      "1  1\n",
      "6  0\n",
      "9  9\n",
      "1  1\n",
      "4  4\n",
      "4  4\n",
      "5  5\n",
      "4  4\n",
      "0  0\n",
      "6  6\n",
      "2  2\n",
      "2  3\n",
      "3  3\n",
      "1  1\n",
      "5  8\n",
      "1  1\n",
      "2  2\n",
      "0  0\n",
      "3  3\n",
      "8  8\n",
      "1  1\n",
      "2  2\n",
      "6  6\n",
      "7  9\n",
      "1  1\n",
      "6  6\n",
      "2  2\n",
      "3  3\n",
      "9  9\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "2  2\n",
      "0  0\n",
      "8  8\n",
      "9  9\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "for i in range(len(predictions)):\n",
    "    x=get_index(predictions[i])\n",
    "    y.append(x)\n",
    "for i in range(len(y)):\n",
    "    print(actual[i],\"\",y[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
